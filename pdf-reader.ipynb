{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c40f792b",
   "metadata": {},
   "source": [
    "# PymuPDF reader\n",
    "- Read the tutorial here: https://pymupdf.readthedocs.io/en/latest/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bec2efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyMuPDF v1.26.3 from /Users/chandlershortlidge/Desktop/Ironhack/resume-reader/.venv/lib/python3.12/site-packages/fitz/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# automatically reload modules, including the ones you wrote yourself\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import fitz\n",
    "import re\n",
    "\n",
    "import pdf_processor as ppr\n",
    "\n",
    "print(f\"Using PyMuPDF v{fitz.__version__} from {fitz.__file__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7df53e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESUME_PATH = \"data-scientist-resume-example.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8304433b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded document with 1 pages\n",
      "format: PDF 1.4\n",
      "title: \n",
      "author: \n",
      "subject: \n",
      "keywords: \n",
      "creator: \n",
      "producer: PDFShift.io\n",
      "creationDate: D:20220728203846+00'00'\n",
      "modDate: D:20220728203846+00'00'\n",
      "trapped: \n",
      "encryption: None\n"
     ]
    }
   ],
   "source": [
    "doc = ppr.load_file(RESUME_PATH)\n",
    "ppr.report_metadata(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9e08cb",
   "metadata": {},
   "source": [
    "### Keyword Searching\n",
    "- To locate where a term appears on the page (useful for highlighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70014b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 'Python' on page 1\n",
      "Found 'SQL' on page 1\n",
      "Found 'AWS' on page 1\n",
      "Found 'Data Scientist' on page 1\n",
      "Saved highlighted PDF as: my_highlighted_resume.pdf\n"
     ]
    }
   ],
   "source": [
    "# Define the keywords you want to find\n",
    "keywords_to_find = [\"Python\", \"SQL\", \"AWS\", \"Data Scientist\"]\n",
    "\n",
    "# Call your new function to highlight the keywords\n",
    "doc = ppr.highlight_keywords(doc, keywords_to_find)\n",
    "\n",
    "# save PDF with highlights\n",
    "ppr.save_highlighted_doc(doc, \"my_highlighted_resume.pdf\")              \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "972645d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown file regenerated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Call the function, which returns a single formatted string\n",
    "markdown_output = ppr.pdf_to_markdown(doc)\n",
    "\n",
    "# Write that string to the .md file\n",
    "with open(\"KANDACE_LOUDOR_new.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_output)\n",
    "\n",
    "print(\"Markdown file regenerated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea5b893",
   "metadata": {},
   "source": [
    "### Extracting Text and Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f663cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from each page\n",
    "\n",
    "for page_num in range(doc.page_count):\n",
    "    page = doc.load_page(page_num)\n",
    "    text = page.get_text()\n",
    "\n",
    "#close when done\n",
    "# doc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88139888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KANDACE LOUDOR\\nDATA SCIENTIST\\nCONTACT\\nkloudor@email.com\\n(123) 456-7890\\nMount Laurel, NJ\\nLinkedIn\\nGithub\\nEDUCATION\\nB.S.\\nStatistics\\nRutgers University\\nSeptember 2011 - April 2015\\nNew Brunswick, NJ\\nSKILLS\\nPython (NumPy, Pandas,\\nScikit-learn, Keras, Flask)\\nSQL (MySQL, Postgres)\\nGit\\nTime Series Forecasting\\nProductionizing Models\\nRecommendation Engines\\nCustomer Segmentation\\nAWS\\nWORK EXPERIENCE\\nData Scientist\\nGrubhub\\nJune 2018 - current / Princeton, NJ\\nDeployed a recommendation engine to production to\\nconditionally recommend other menu items based on past order\\nhistory, increasing average order size by 7%\\nImplemented various time series forecasting techniques to\\npredict surge in orders, lowering customer wait by 10 minutes\\nDesigned a model in a pilot to increase incentives for drivers\\nduring peak hours, increasing driver availability by 22%\\nLed a team of 3 data scientist to model the ordering process 5\\nunique ways, reported results, and made recommendations to\\nincrease order output by 9%\\nData Scientist\\nSpectrix Analytical Services\\nMarch 2016 - June 2018 / Princeton, NJ\\nBuilt a customer attrition random forest model that improved\\nmonthly retention by 12 basis points for clients likely to opt-out\\nby providing relevant product features for them\\nCoordinated with the product and marketing teams to determine\\nwhat kind of client interactions resulted in maximized service\\nopt-ins, increasing conversions by 18%\\nPartnered with product team to create a production\\nrecommendation engine in Python that improved the length on-\\npage for users with $225K in incremental annual revenue\\nCompiled and analyzed data surrounding the prototypes for a\\nprosthesis, which saved over $1M in its creation\\nEntry-Level Data Analyst\\nAvenica\\nApril 2015 - March 2016 / Mount Laurel, NJ\\nCollaborated with product managers to perform cohort analysis\\nthat identified an opportunity to reduce pricing by 21% for a\\nsegment of users to boost yearly revenue by $560,000\\nConstructed operational reporting in Tableau to improve\\nscheduling contractors, saving $90,000 in the annual budget\\nImplemented a long-term pricing experiment that improved\\ncustomer lifetime value by 23%\\nRan, submitted, and reported on monthly client enrollments,\\nservices opted in for, and the employees assigned to clients\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acbe837",
   "metadata": {},
   "source": [
    "### get_links()\n",
    "- https://pymupdf.readthedocs.io/en/latest/page.html#Page.get_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bed2e33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 links:\n",
      "  -> URI: https://linkedin.com/\n",
      "    location on page: Rect(116.25, 190.5, 160.5, 205.5)\n",
      "  -> URI: https://github.com/\n",
      "    location on page: Rect(125.25, 206.25, 160.5, 221.25)\n"
     ]
    }
   ],
   "source": [
    "# Loop through pages and inspect links\n",
    "# LET'S REWRITE IT **UNDERSTANDING** WHAT IT DOES\n",
    "# everything begins with http or htto\n",
    "for page_num in range(doc.page_count):\n",
    "    page = doc.load_page(page_num) \n",
    "    links = page.links() # list of link-dicts from page\n",
    "\n",
    "    if not links:\n",
    "        continue\n",
    "\n",
    "    print(f\"Page {page_num + 1} links:\")\n",
    "    for link in links: \n",
    "    # Common keys: 'kind', 'from', and either 'uri' or 'xref'/'to'\n",
    "        kind = link[\"kind\"]\n",
    "        location = link[\"from\"] # where the link is located\n",
    "        uri = link.get(\"uri\") # external URL, if any\n",
    "        to = link.get(\"to\") # (page, ...) for internal jumps\n",
    "\n",
    "        if uri:\n",
    "            print(f\"  -> URI: {uri}\")\n",
    "        elif to:\n",
    "            print(f\"  → Internal link to page {to[0] + 1}\")\n",
    "        else:\n",
    "            print(\"  → Other link kind:\", kind)\n",
    "\n",
    "        print(f\"    location on page: {location}\")    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume-reader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
