{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c40f792b",
   "metadata": {},
   "source": [
    "# PymuPDF reader\n",
    "- Read the tutorial here: https://pymupdf.readthedocs.io/en/latest/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bec2efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using PyMuPDF v1.26.3 from /Users/chandlershortlidge/Desktop/Ironhack/resume-reader/.venv/lib/python3.12/site-packages/fitz/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# automatically reload modules, including the ones you wrote yourself\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import fitz\n",
    "import re\n",
    "\n",
    "import pdf_processor as ppr\n",
    "\n",
    "print(f\"Using PyMuPDF v{fitz.__version__} from {fitz.__file__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7df53e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESUME_PATH = \"data-scientist-resume-example.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8304433b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded document with 1 pages\n",
      "format: PDF 1.4\n",
      "title: \n",
      "author: \n",
      "subject: \n",
      "keywords: \n",
      "creator: \n",
      "producer: PDFShift.io\n",
      "creationDate: D:20220728203846+00'00'\n",
      "modDate: D:20220728203846+00'00'\n",
      "trapped: \n",
      "encryption: None\n"
     ]
    }
   ],
   "source": [
    "doc = ppr.load_file(RESUME_PATH)\n",
    "ppr.report_metadata(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea5b893",
   "metadata": {},
   "source": [
    "### Extracting Text and Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f663cfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Extract text from each page\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m page_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mdoc\u001b[49m.page_count):\n\u001b[32m      4\u001b[39m     page = doc.load_page(page_num)\n\u001b[32m      5\u001b[39m     text = page.get_text()\n",
      "\u001b[31mNameError\u001b[39m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract text from each page\n",
    "\n",
    "for page_num in range(doc.page_count):\n",
    "    page = doc.load_page(page_num)\n",
    "    text = page.get_text()\n",
    "\n",
    "#close when done\n",
    "# doc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88139888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KANDACE LOUDOR\\nDATA SCIENTIST\\nCONTACT\\nkloudor@email.com\\n(123) 456-7890\\nMount Laurel, NJ\\nLinkedIn\\nGithub\\nEDUCATION\\nB.S.\\nStatistics\\nRutgers University\\nSeptember 2011 - April 2015\\nNew Brunswick, NJ\\nSKILLS\\nPython (NumPy, Pandas,\\nScikit-learn, Keras, Flask)\\nSQL (MySQL, Postgres)\\nGit\\nTime Series Forecasting\\nProductionizing Models\\nRecommendation Engines\\nCustomer Segmentation\\nAWS\\nWORK EXPERIENCE\\nData Scientist\\nGrubhub\\nJune 2018 - current / Princeton, NJ\\nDeployed a recommendation engine to production to\\nconditionally recommend other menu items based on past order\\nhistory, increasing average order size by 7%\\nImplemented various time series forecasting techniques to\\npredict surge in orders, lowering customer wait by 10 minutes\\nDesigned a model in a pilot to increase incentives for drivers\\nduring peak hours, increasing driver availability by 22%\\nLed a team of 3 data scientist to model the ordering process 5\\nunique ways, reported results, and made recommendations to\\nincrease order output by 9%\\nData Scientist\\nSpectrix Analytical Services\\nMarch 2016 - June 2018 / Princeton, NJ\\nBuilt a customer attrition random forest model that improved\\nmonthly retention by 12 basis points for clients likely to opt-out\\nby providing relevant product features for them\\nCoordinated with the product and marketing teams to determine\\nwhat kind of client interactions resulted in maximized service\\nopt-ins, increasing conversions by 18%\\nPartnered with product team to create a production\\nrecommendation engine in Python that improved the length on-\\npage for users with $225K in incremental annual revenue\\nCompiled and analyzed data surrounding the prototypes for a\\nprosthesis, which saved over $1M in its creation\\nEntry-Level Data Analyst\\nAvenica\\nApril 2015 - March 2016 / Mount Laurel, NJ\\nCollaborated with product managers to perform cohort analysis\\nthat identified an opportunity to reduce pricing by 21% for a\\nsegment of users to boost yearly revenue by $560,000\\nConstructed operational reporting in Tableau to improve\\nscheduling contractors, saving $90,000 in the annual budget\\nImplemented a long-term pricing experiment that improved\\ncustomer lifetime value by 23%\\nRan, submitted, and reported on monthly client enrollments,\\nservices opted in for, and the employees assigned to clients\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf443d8",
   "metadata": {},
   "source": [
    "### Keyword Searching\n",
    "- To locate where a term appears on the page (useful for highlighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9076d2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 'Data Scientist' on page 1\n",
      "Saved highlighted PDF as: my_highlighted_resume.pdf\n"
     ]
    }
   ],
   "source": [
    "# Define the keywords you want to find\n",
    "keywords_to_find = [\"Python\", \"SQL\", \"AWS\", \"Data Scientist\"]\n",
    "\n",
    "# Call your new function to highlight the keywords\n",
    "doc = ppr.highlight_keywords(doc, keywords_to_find)\n",
    "\n",
    "# save PDF with highlights\n",
    "ppr.save_highlighted_doc(doc, \"my_highlighted_resume.pdf\")              \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acbe837",
   "metadata": {},
   "source": [
    "### get_links()\n",
    "- https://pymupdf.readthedocs.io/en/latest/page.html#Page.get_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2e33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 links:\n",
      "  → URI: https://linkedin.com/\n",
      "    location on page: Rect(116.25, 190.5, 160.5, 205.5)\n",
      "  → URI: https://github.com/\n",
      "    location on page: Rect(125.25, 206.25, 160.5, 221.25)\n"
     ]
    }
   ],
   "source": [
    "# Loop through pages and inspect links\n",
    "# LET'S REWRITE IT **UNDERSTANDING** WHAT IT DOES\n",
    "# everything begins with http or htto\n",
    "for page_num in range(doc.page_count):\n",
    "    page = doc.load_page(page_num) \n",
    "    links = page.links() # list of link-dicts from page\n",
    "\n",
    "    if not links:\n",
    "        continue\n",
    "\n",
    "    print(f\"Page {page_num + 1} links:\")\n",
    "    for link in links: \n",
    "    # Common keys: 'kind', 'from', and either 'uri' or 'xref'/'to'\n",
    "        kind = link[\"kind\"]\n",
    "        location = link[\"from\"] # where the link is located\n",
    "        uri = link.get(\"uri\") # external URL, if any\n",
    "        to = link.get(\"to\") # (page, ...) for internal jumps\n",
    "\n",
    "        if uri:\n",
    "            print(f\"  -> URI: {uri}\")\n",
    "        elif to:\n",
    "            print(f\"  → Internal link to page {to[0] + 1}\")\n",
    "        else:\n",
    "            print(\"  → Other link kind:\", kind)\n",
    "\n",
    "        print(f\"    location on page: {location}\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42dfcb1",
   "metadata": {},
   "source": [
    "## Convert to markdown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2549635f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted /Users/eliza/Desktop/resume-reader/data-scientist-resume-example.pdf → output.md\n"
     ]
    }
   ],
   "source": [
    "def pdf_to_markdown(pdf_path, md_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    md_lines = []\n",
    "\n",
    "    for p in range(doc.page_count):\n",
    "        page = doc.load_page(p)\n",
    "        # get a nested dict of blocks → lines → spans\n",
    "        page_dict = page.get_text(\"dict\")\n",
    "\n",
    "        for block in page_dict[\"blocks\"]:\n",
    "            # Only text blocks (ignore images, drawings)\n",
    "            if block[\"type\"] != 0:\n",
    "                continue\n",
    "\n",
    "            # Join all spans in this block into one text string\n",
    "            text = \" \".join(span[\"text\"] for line in block[\"lines\"] for span in line[\"spans\"])\n",
    "            text = text.strip()\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            #  Simple heuristic: ALL CAPS + short → H2\n",
    "            if text.isupper() and len(text) < 60:\n",
    "                md_lines.append(f\"## {text.title()}\")\n",
    "                continue\n",
    "\n",
    "            # Detect bullet lists (e.g. lines starting with • or –)\n",
    "            if re.match(r\"^[•\\-\\u2022]\\s+\", text):\n",
    "                item = re.sub(r\"^[•\\-\\u2022]\\s+\", \"\", text)\n",
    "                md_lines.append(f\"-{item}\")\n",
    "                continue\n",
    "\n",
    "            # Otherwise treat as paragraph\n",
    "            md_lines.append(text)\n",
    "\n",
    "        # Add a page break marker (optional)\n",
    "        md_lines.append(\"\\n---\\n\")\n",
    "\n",
    "        \n",
    "\n",
    "# Write out the Markdown\n",
    "    with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\\n\".join(md_lines))\n",
    "\n",
    "    print(f\"Converted {pdf_path} → {md_path}\")\n",
    "\n",
    "# Usage\n",
    "pdf_to_markdown(RESUME_PATH, \"output.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bee1479c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# (Keep your other functions like load_file, highlight_keywords, etc.)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m markdown_output = \u001b[43mppr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:7\u001b[39m, in \u001b[36mconvert_to_markdown\u001b[39m\u001b[34m(doc)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Ironhack/resume-reader/.venv/lib/python3.12/site-packages/pymupdf/utils.py:941\u001b[39m, in \u001b[36mget_text\u001b[39m\u001b[34m(page, option, clip, flags, textpage, sort, delimiters, tolerance)\u001b[39m\n\u001b[32m    928\u001b[39m formats = {\n\u001b[32m    929\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: pymupdf.TEXTFLAGS_TEXT,\n\u001b[32m    930\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhtml\u001b[39m\u001b[33m\"\u001b[39m: pymupdf.TEXTFLAGS_HTML,\n\u001b[32m   (...)\u001b[39m\u001b[32m    938\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mblocks\u001b[39m\u001b[33m\"\u001b[39m: pymupdf.TEXTFLAGS_BLOCKS,\n\u001b[32m    939\u001b[39m }\n\u001b[32m    940\u001b[39m option = option.lower()\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m option \u001b[38;5;129;01min\u001b[39;00m formats\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m option \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m formats:\n\u001b[32m    943\u001b[39m     option = \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# (Keep your other functions like load_file, highlight_keywords, etc.)\n",
    "\n",
    "markdown_output = ppr.convert_to_markdown(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29a23e0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'markdown_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m output_filename = \u001b[33m\"\u001b[39m\u001b[33mKANDACE_LOUDOR.md\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_filename, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     f.write(\u001b[43mmarkdown_output\u001b[49m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSuccessfully converted and saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'markdown_output' is not defined"
     ]
    }
   ],
   "source": [
    "# 3. Now you can save that string to a file\n",
    "output_filename = \"KANDACE_LOUDOR.md\"\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_output)\n",
    "\n",
    "print(f\"Successfully converted and saved to {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume-reader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
