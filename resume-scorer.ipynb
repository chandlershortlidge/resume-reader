{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f5e3a3",
   "metadata": {},
   "source": [
    "## 1. Define Your Keyword/Phrase List\n",
    "First, collect the terms you care about into two categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d27682a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "with open(\"output.md\", encoding=\"utf-8\") as f:\n",
    "    raw_md = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc6df8",
   "metadata": {},
   "source": [
    "### 2. Preprocess the Resume Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d9f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define your normalize() helper\n",
    "def normalize(text):\n",
    "    text = text.lower() # lowercase everything\n",
    "    # strip out link syntax [text](url) → text\n",
    "    text = re.sub(r\"\\[([^\\]]+)\\]\\([^)]+\\)\", r\"\\1\", text)\n",
    "    # remove Markdown headers (##, ###, …), bullets (-, *) and code backticks\n",
    "    text = re.sub(r\"^#{1,6}\\s*|^[-*]\\s+|`+\", \"\", text, flags=re.MULTILINE)\n",
    "    # collapse any other punctuation to spaces\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae1020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Normalize the raw Markdown\n",
    "clean_text = normalize(raw_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3834430",
   "metadata": {},
   "outputs": [],
   "source": [
    "required = [t.lower() for t in [\n",
    "  \"LLMs\", \"prompt engineering\", \"embeddings\", \"RAG workflows\",\n",
    "  \"Python\", \"LangChain\", \"spaCy\", \"knowledge extraction\", \"Data Scientist\"\n",
    "]]\n",
    "optional = [t.lower() for t in  [\n",
    "  \"TensorFlow\", \"Keras\", \"PyTorch\",\n",
    "  \"vector database\", \"SQL\", \"Pandas\", \"FAISS\", \"document AI\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da45b9c",
   "metadata": {},
   "source": [
    "### 3. Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a7a5f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Score!\n",
    "score = 0\n",
    "found_terms = set()\n",
    "\n",
    "for term in required:\n",
    "    if term in clean_text:\n",
    "        score +=1 # full point\n",
    "        found_terms.add(term)\n",
    "\n",
    "    for term in optional:\n",
    "        if term in clean_text:\n",
    "            score += 0.5 #half-point\n",
    "            found_terms.add(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c0f41fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate score: 21.0 out of 13.0 (162%)\n"
     ]
    }
   ],
   "source": [
    "# normalzie score scale\n",
    "max_points = len(required) * 1 + len(optional) * 0.5\n",
    "percent = (score / max_points) * 100\n",
    "\n",
    "print(f\"Candidate score: {score} out of {max_points} ({percent:.0f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cd44b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elizaveta guseva  phd\n",
      "\n",
      "liza guseva hey com\n",
      "\n",
      " 657 141 280  barcelona  spain   linkedin  elizaguseva    ml ai skills   ml ai research  system design  productionization  a b testing  genai  agentic ai  r ...\n"
     ]
    }
   ],
   "source": [
    "# 6. Inspect intermediate text (optional)\n",
    "print(clean_text[:200], \"...\")  # see first 200 chars of cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49cfd368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched terms: ['data scientist', 'keras', 'pandas', 'python', 'sql']\n",
      "Raw score: 15.5 / 13.0\n",
      "Percentage match: 119.2%\n"
     ]
    }
   ],
   "source": [
    "# 6. Report\n",
    "print(f\"Matched terms: {sorted(found_terms)}\")\n",
    "print(f\"Raw score: {score} / {max_points}\")\n",
    "print(f\"Percentage match: {percent:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85146036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "824bf7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "patterns = [nlp.make_doc(term) for term in required + optional]\n",
    "matcher.add(\"SKILL_MATCH\", patterns)\n",
    "\n",
    "doc = nlp(raw_md)\n",
    "matches = matcher(doc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ea356ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python → True\n",
      "pandas → True\n",
      "keras → True\n"
     ]
    }
   ],
   "source": [
    "# 1. Confirm presence\n",
    "for term in [\"python\", \"pandas\", \"keras\"]:\n",
    "    print(term, \"→\", term in clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1006b581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "…enai  agentic ai  retrieval  evals    techstack   python  sql  docker  fastapi flask  rest  langchai…\n",
      "\n",
      "…flask  rest  langchain  pydanticai  ml libraries  pandas  numpy   sklearn  keras  experience  self e…\n",
      "\n",
      "…ydanticai  ml libraries  pandas  numpy   sklearn  keras  experience  self employed  founder  ml ai c…\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. If found, show a snippet around the first occurrence\n",
    "for term in [\"python\", \"pandas\", \"keras\"]:\n",
    "    idx = clean_text.find(term)\n",
    "    if idx != -1:\n",
    "        start = max(0, idx - 50)\n",
    "        end   = min(len(clean_text), idx + 50)\n",
    "        snippet = clean_text[start:end].replace(\"\\n\", \" \")\n",
    "        print(f\"\\n…{snippet}…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a334be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
