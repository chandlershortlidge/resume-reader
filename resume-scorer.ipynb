{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f5e3a3",
   "metadata": {},
   "source": [
    "## 1. Define Your Keyword/Phrase List\n",
    "First, collect the terms you care about into two categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d27682a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "file_path = \"/mnt/data/KANDACE_LOUDOR.md\"\n",
    "with open(\"KANDACE_LOUDOR.md\", encoding=\"utf-8\") as f:\n",
    "    raw_md = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc6df8",
   "metadata": {},
   "source": [
    "### 2. Preprocess the Resume Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d9f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define your normalize() helper\n",
    "def normalize(text):\n",
    "    text = text.lower() # lowercase everything\n",
    "    # strip out link syntax [text](url) → text\n",
    "    text = re.sub(r\"\\[([^\\]]+)\\]\\([^)]+\\)\", r\"\\1\", text)\n",
    "    # remove Markdown headers (##, ###, …), bullets (-, *) and code backticks\n",
    "    text = re.sub(r\"^#{1,6}\\s*|^[-*]\\s+|`+\", \"\", text, flags=re.MULTILINE)\n",
    "    # collapse any other punctuation to spaces\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae1020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Normalize the raw Markdown\n",
    "clean_text = normalize(raw_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3834430",
   "metadata": {},
   "outputs": [],
   "source": [
    "required = [t.lower() for t in [\n",
    "  \"LLMs\", \"prompt engineering\", \"embeddings\", \"RAG workflows\",\n",
    "  \"Python\", \"LangChain\", \"spaCy\", \"knowledge extraction\", \"Data Scientist\"\n",
    "]]\n",
    "optional = [t.lower() for t in  [\n",
    "  \"TensorFlow\", \"Keras\", \"PyTorch\",\n",
    "  \"vector database\", \"SQL\", \"Pandas\", \"FAISS\", \"document AI\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ab125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity: any accidental overlap?\n",
    "overlap = set(required) & set(optional)\n",
    "if overlap:\n",
    "    print(\"WARNING overlap between required/optional:\", overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba8ecfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- match as unique sets ---\n",
    "req_found = {t for t in required if t in clean_text}\n",
    "opt_found = {t for t in optional if t in clean_text}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da45b9c",
   "metadata": {},
   "source": [
    "### 3. Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a7a5f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Score!\n",
    "score = 0\n",
    "found_terms = set()\n",
    "\n",
    "# Score required = 1 point each\n",
    "for term in required:\n",
    "    if term in clean_text:\n",
    "        score +=1 # full point\n",
    "        found_terms.add(term)\n",
    "        \n",
    "# Score optional = 0.5 points each\n",
    "    for term in optional:\n",
    "        if term in clean_text:\n",
    "            score += 0.5 #half-point\n",
    "            found_terms.add(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c0f41fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute percentage\n",
    "max_points = len(required) * 1 + len(optional) * 0.5\n",
    "percent = (score / max_points) * 100 if max_points else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cd44b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kandace loudor\n",
      "\n",
      "data scientist\n",
      "\n",
      "contact\n",
      "\n",
      "kloudor email com\n",
      "\n",
      " 123  456 7890 mount laurel  nj\n",
      "\n",
      "linkedin\n",
      "\n",
      "github\n",
      "\n",
      "education\n",
      "\n",
      "b s  statistics rutgers university september 2011   april 2015\n",
      "\n",
      "new brunswick  ...\n"
     ]
    }
   ],
   "source": [
    "# 6. Inspect intermediate text (optional)\n",
    "print(clean_text[:200], \"...\")  # see first 200 chars of cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cfd368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required matched: ['data scientist', 'python']\n",
      "Optional matched: ['keras', 'pandas', 'sql']\n",
      "Raw score: 15.5 / 13.0\n",
      "Percentage match: 119.2%\n"
     ]
    }
   ],
   "source": [
    "# 6. Report\n",
    "print(\"Required matched:\", sorted(req_found))\n",
    "print(\"Optional matched:\", sorted(opt_found))\n",
    "print(f\"Raw score: {score} / {max_points}\")\n",
    "print(f\"Percentage match: {percent:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85146036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "824bf7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "patterns = [nlp.make_doc(term) for term in required + optional]\n",
    "matcher.add(\"SKILL_MATCH\", patterns)\n",
    "\n",
    "doc = nlp(\"KANDACE_LOUDOR.md\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ea356ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python → True\n",
      "pandas → True\n",
      "keras → True\n"
     ]
    }
   ],
   "source": [
    "# 1. Confirm presence\n",
    "for term in [\"python\", \"pandas\", \"keras\"]:\n",
    "    print(term, \"→\", term in clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1006b581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "…ber 2011   april 2015  new brunswick  nj  skills  python  numpy  pandas   scikit learn  keras  flask…\n",
      "\n",
      "…l 2015  new brunswick  nj  skills  python  numpy  pandas   scikit learn  keras  flask   sql  mysql  …\n",
      "\n",
      "…nj  skills  python  numpy  pandas   scikit learn  keras  flask   sql  mysql  postgres   git time ser…\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. If found, show a snippet around the first occurrence\n",
    "for term in [\"python\", \"pandas\", \"keras\"]:\n",
    "    idx = clean_text.find(term)\n",
    "    if idx != -1:\n",
    "        start = max(0, idx - 50)\n",
    "        end   = min(len(clean_text), idx + 50)\n",
    "        snippet = clean_text[start:end].replace(\"\\n\", \" \")\n",
    "        print(f\"\\n…{snippet}…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a334be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
